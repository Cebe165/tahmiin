# -*- coding: utf-8 -*-
"""tahmiin

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xLD48LHiVtQ0u5cYf6JHGnGvrXWjZTEs
"""

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler
import os

def load_data(file_path, sequence_length=3):
    file_path = os.path.join(os.path.dirname(__file__), 'data.csv')
    df = pd.read_csv(file_path)
    data = df.values.reshape(-1, 1)
    scaler = MinMaxScaler(feature_range=(0, 1))
    data_normalized = scaler.fit_transform(data)
    X, y = [], []
    for i in range(len(data_normalized) - sequence_length):
        X.append(data_normalized[i:i+sequence_length])
        y.append(data_normalized[i+sequence_length])
    X = np.array(X)
    y = np.array(y)
    return X, y, scaler

def build_model(input_shape):
    model = Sequential()
    model.add(LSTM(50, activation='relu', input_shape=input_shape))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mse')
    return model

def predict_next_number(model, last_sequence, scaler):
    last_sequence_normalized = scaler.transform(last_sequence.reshape(-1, 1))
    last_sequence_normalized = last_sequence_normalized.reshape(1, -1, 1)
    predicted_normalized = model.predict(last_sequence_normalized)
    predicted = scaler.inverse_transform(predicted_normalized)
    return predicted[0][0]

def main():
    file_path = "data.csv"
    sequence_length = 3
    epochs = 200
    X, y, scaler = load_data(file_path, sequence_length)
    model = build_model((X.shape[1], X.shape[2]))
    model.fit(X, y, epochs=epochs, verbose=1)
    last_sequence = pd.read_csv(file_path).values[-sequence_length:]
    prediction = predict_next_number(model, last_sequence, scaler)
    print(f"\nTahmin Edilen Sonraki Sayı: {prediction:.2f}")
    output_path = "tahmin_sonuclari.txt"
    with open(output_path, "a") as f:
        f.write(f"Son Sequence: {last_sequence.ravel()}, Tahmin: {prediction:.2f}\n")
    print(f"Tahmin sonucu '{output_path}' dosyasına kaydedildi.")

if __name__ == "__main__":
    main()

from flask import Flask, request, jsonify
import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler

app = Flask(__name__)

def load_model():
    df = pd.read_csv('/content/data.csv')
    data = df.values.reshape(-1, 1)
    scaler = MinMaxScaler(feature_range=(0, 1))
    data_normalized = scaler.fit_transform(data)
    sequence_length = 3
    X, y = [], []
    for i in range(len(data_normalized) - sequence_length):
        X.append(data_normalized[i:i+sequence_length])
        y.append(data_normalized[i+sequence_length])
    X = np.array(X)
    y = np.array(y)
    model = Sequential()
    model.add(LSTM(50, activation='relu', input_shape=(sequence_length, 1)))
    model.add(Dense(1))
    model.compile(optimizer='adam', loss='mse')
    model.fit(X, y, epochs=200, verbose=0)
    return model, scaler

model, scaler = load_model()

@app.route('/predict', methods=['POST'])
def predict():
    data = request.json['sequence']
    last_sequence = np.array(data).reshape(-1, 1)
    last_sequence_normalized = scaler.transform(last_sequence)
    last_sequence_normalized = last_sequence_normalized.reshape(1, sequence_length, 1)
    prediction = model.predict(last_sequence_normalized)
    prediction = scaler.inverse_transform(prediction)
    return jsonify({"prediction": float(prediction[0][0])})

if __name__ == '__main__':
    app.run()
